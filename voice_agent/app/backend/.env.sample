
AZURE_OPENAI_ENDPOINT="https://.openai.azure.com/"
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_EMB_ENDPOINT= [Optional] if different from your realtime endpoint
AZURE_OPENAI_EMB_API_KEY= [Optional] if providing an embedding endpoint
AZURE_OPENAI_EMB_DEPLOYMENT="text-embedding-ada-002"
AZURE_OPENAI_4O_MINI_DEPLOYMENT=YOUR_AZURE_OPENAI_4O_MINI_DEPLOYMENT_NAME
# INTENT_SHIFT_API_KEY= #this is only needed if you use a custom trained model for intent classification
# INTENT_SHIFT_API_URL=https://YOUR_ML_DEPLOYMENT.westus2.inference.ml.azure.com/score
# INTENT_SHIFT_API_DEPLOYMENT=YOUR_ML_DEPLOYMENT_NAME
AZURE_OPENAI_API_VERSION=2024-10-01-preview
AZURE_OPENAI_REALTIME_DEPLOYMENT_NAME=gpt-4o-realtime-preview
VOICE_NAME=shimmer
TRANSCRIPTION_MODEL=whisper-1
TURN_DETECTION_MODEL=server_vad
TURN_DETECTION_THRESHOLD=0.5
TURN_DETECTION_PREFIX_PADDING_MS=300
TURN_DETECTION_SILENCE_DURATION_MS=200
AZURE_REDIS_ENDPOINT=#optional, if you want to use redis for caching which support distributed caching for high
AZURE_REDIS_KEY=
